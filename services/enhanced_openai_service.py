# -*- coding: utf-8 -*-
"""
Enhanced OpenAI service with better error handling and rate limiting
"""

import os
import openai
from openai import OpenAI
import time
import json
from typing import Optional, List, Dict
from dataclasses import dataclass, asdict
from dotenv import load_dotenv
import backoff

# Load environment variables
load_dotenv()


@dataclass
class GeneratedChoice:
    """Generated choice data structure"""
    content: str
    is_correct: bool


@dataclass 
class GeneratedQuestion:
    """Generated question data structure"""
    title: str
    content: str
    category: str
    explanation: str
    difficulty: str
    choices: List[GeneratedChoice]


class EnhancedOpenAIService:
    """Enhanced OpenAI service with better error handling"""
    
    # Available models
    AVAILABLE_MODELS = {
        "gpt-3.5-turbo": {
            "name": "GPT-3.5 Turbo",
            "description": "é«˜é€Ÿã§çµŒæ¸ˆçš„ã€æ—¥å¸¸çš„ãªå•é¡Œç”Ÿæˆã«é©ã—ã¦ã„ã‚‹",
            "cost": "ä½",
            "quality": "è‰¯"
        },
        "gpt-4o-mini": {
            "name": "GPT-4o Mini", 
            "description": "GPT-4ã®è»½é‡ç‰ˆã€é«˜å“è³ªã§çµŒæ¸ˆçš„",
            "cost": "ä¸­",
            "quality": "å„ª"
        },
        "gpt-4o": {
            "name": "GPT-4o",
            "description": "æœ€é«˜å“è³ªã®å•é¡Œç”Ÿæˆã€è¤‡é›‘ãªå†…å®¹ã«å¯¾å¿œ",
            "cost": "é«˜",
            "quality": "æœ€å„ª"
        },
        "gpt-4": {
            "name": "GPT-4",
            "description": "é«˜å“è³ªãªå•é¡Œç”Ÿæˆã€è©³ç´°ãªè§£èª¬",
            "cost": "é«˜",
            "quality": "æœ€å„ª"
        }
    }
    
    def __init__(self, model: str = "gpt-3.5-turbo", model_name: str = None):
        print("Initializing EnhancedOpenAIService...")
        
        # Use model_name if provided, otherwise use model parameter
        selected_model = model_name if model_name is not None else model
        
        # Check API key
        self.api_key = os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            print("ERROR: OPENAI_API_KEY environment variable is not set")
            raise ValueError("OPENAI_API_KEY environment variable is not set")
        
        print(f"API Key found: {self.api_key[:10]}...{self.api_key[-4:]}")
        
        # Validate and set model
        if selected_model not in self.AVAILABLE_MODELS:
            print(f"Warning: Model {selected_model} not in available models, using gpt-3.5-turbo")
            selected_model = "gpt-3.5-turbo"
        
        self.model = selected_model
        print(f"Using model: {self.model} ({self.AVAILABLE_MODELS[self.model]['name']})")
        
        # Initialize OpenAI client with enhanced connection settings
        try:
            self.client = OpenAI(
                api_key=self.api_key,
                timeout=60.0,  # 60ç§’ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
                max_retries=3,  # å†…è”µãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½
                base_url="https://api.openai.com/v1"  # æ˜ç¤ºçš„ãªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
            )
            print("OpenAI client initialized successfully")
        except Exception as e:
            print(f"ERROR: Failed to initialize OpenAI client: {e}")
            raise ConnectionError(f"Failed to initialize OpenAI client: {e}")
        
        self.max_retries = 5  # ãƒªãƒˆãƒ©ã‚¤å›æ•°ã‚’å¢—åŠ 
        self.retry_delay = 2.0  # åˆæœŸé…å»¶ã‚’å¢—åŠ 
    
    def generate_question(
        self,
        category: str = "åŸºæœ¬æƒ…å ±æŠ€è¡“è€…",
        difficulty: str = "medium",
        topic: Optional[str] = None,
        question_type: str = "multiple_choice",
        language: str = "japanese",
        allow_multiple_correct: bool = False
    ) -> Optional[GeneratedQuestion]:
        """
        Generate a question with enhanced options and error handling
        
        Args:
            category: å•é¡Œã‚«ãƒ†ã‚´ãƒª
            difficulty: é›£æ˜“åº¦
            topic: ç‰¹å®šã®ãƒˆãƒ”ãƒƒã‚¯ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            question_type: å•é¡Œã‚¿ã‚¤ãƒ—
            language: è¨€èª
            allow_multiple_correct: è¤‡æ•°ã®æ­£è§£ã‚’è¨±å¯ã™ã‚‹ã‹ã©ã†ã‹
        """
        
        prompt = self._create_enhanced_prompt(
            category=category,
            difficulty=difficulty,
            topic=topic,
            question_type=question_type,
            language=language,
            allow_multiple_correct=allow_multiple_correct
        )
        
        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system", 
                            "content": "ã‚ãªãŸã¯è³‡æ ¼è©¦é¨“å•é¡Œä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚æ­£ç¢ºã§æ•™è‚²çš„ãªå•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
                        },
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=1500,
                    temperature=0.7,
                    response_format={"type": "json_object"},
                    # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·: ãƒ‡ãƒ¼ã‚¿ã®å­¦ç¿’ã‚’ç„¡åŠ¹åŒ–
                    extra_headers={
                        "X-OpenAI-Skip-Training": "true"
                    }
                )
                
                # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®ç¢ºèªãƒ­ã‚°
                print("PRIVACY: OpenAIå­¦ç¿’ç„¡åŠ¹åŒ–ãƒ˜ãƒƒãƒ€ãƒ¼é€ä¿¡å®Œäº†")
                
                content = response.choices[0].message.content
                print(f"ğŸ¤– OpenAI Raw Response Length: {len(content)} characters")
                print(f"ğŸ¤– OpenAI Raw Response Preview: {content[:200]}...")
                
                try:
                    question_data = json.loads(content)
                    print(f"ğŸ“‹ Parsed JSON keys: {list(question_data.keys())}")
                    if 'choices' in question_data:
                        print(f"ğŸ“‹ Choices found in response: {len(question_data['choices'])} items")
                        for i, choice in enumerate(question_data['choices'][:2]):  # æœ€åˆã®2ã¤ã®ã¿è¡¨ç¤º
                            print(f"   Choice {i+1}: {choice}")
                    else:
                        print("âŒ No 'choices' key found in OpenAI response!")
                        print(f"Available keys: {list(question_data.keys())}")
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON parsing failed: {e}")
                    print(f"Raw content: {content}")
                    return None
                
                return self._parse_question_response(question_data, category, difficulty)
                
            except openai.RateLimitError as e:
                if attempt < self.max_retries - 1:
                    wait_time = self.retry_delay * (2 ** attempt)  # Exponential backoff
                    print(f"Rate limit exceeded. Waiting {wait_time}s before retry {attempt + 1}/{self.max_retries}")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"Rate limit exceeded after {self.max_retries} attempts: {e}")
                    return None
                    
            except openai.APIError as e:
                print(f"OpenAI API error on attempt {attempt + 1}: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return None
                    
            except json.JSONDecodeError as e:
                print(f"Failed to parse JSON response on attempt {attempt + 1}: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return None
                    
            except Exception as e:
                print(f"Unexpected error on attempt {attempt + 1}: {e}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return None
        
        return None
    
    def _create_enhanced_prompt(
        self,
        category: str,
        difficulty: str,
        topic: Optional[str],
        question_type: str,
        language: str,
        allow_multiple_correct: bool = False
    ) -> str:
        """Create an enhanced prompt with more specific instructions"""
        
        difficulty_instructions = {
            "easy": "åˆå¿ƒè€…å‘ã‘ã®åŸºæœ¬çš„ãªæ¦‚å¿µã‚’å•ã†å•é¡Œ",
            "medium": "ä¸­ç´šè€…å‘ã‘ã®å®Ÿè·µçš„ãªå•é¡Œ", 
            "hard": "ä¸Šç´šè€…å‘ã‘ã®å¿œç”¨ãƒ»ç™ºå±•å•é¡Œ"
        }
        
        topic_instruction = f"ç‰¹ã«ã€Œ{topic}ã€ã«é–¢é€£ã™ã‚‹å†…å®¹ã§" if topic else ""
        
        # è¤‡æ•°æ­£è§£è¨­å®šã«åŸºã¥ã„ãŸæŒ‡ç¤º
        correct_answer_instruction = "3. æ­£è§£ã¯è¤‡æ•°ã‚ã‚‹å ´åˆã‚‚ã‚ã‚Šã¾ã™" if allow_multiple_correct else "3. æ­£è§£ã¯å¿…ãš1ã¤ã®ã¿"
        
        prompt = f"""
{category}ã®{difficulty_instructions[difficulty]}ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
{topic_instruction}

ä»¥ä¸‹ã®æ¡ä»¶ã«å¾“ã£ã¦ã€JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„ï¼š

**æ¡ä»¶:**
1. å•é¡Œæ–‡ã¯å…·ä½“çš„ã§å®Ÿè·µçš„ãªå†…å®¹ã«ã™ã‚‹
2. é¸æŠè‚¢ã¯å¿…ãš4ã¤ä½œæˆã™ã‚‹ï¼ˆã“ã®æ¡ä»¶ã¯çµ¶å¯¾ã«å®ˆã£ã¦ãã ã•ã„ï¼‰
{correct_answer_instruction}
4. é–“é•ã„ã®é¸æŠè‚¢ã‚‚æ•™è‚²çš„ä¾¡å€¤ãŒã‚ã‚‹ã‚‚ã®ã«ã™ã‚‹
5. è§£èª¬ã¯è©³ã—ãã€ãªãœãã®ç­”ãˆãŒæ­£ã—ã„ã‹ã‚’èª¬æ˜ã™ã‚‹
6. é›£æ˜“åº¦ã€Œ{difficulty}ã€ã«é©ã—ãŸå•é¡Œãƒ¬ãƒ™ãƒ«ã«ã™ã‚‹

**é‡è¦: é¸æŠè‚¢ã¯å¿…ãš4ã¤ä½œæˆã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯å¿…é ˆè¦ä»¶ã§ã™ã€‚**

**JSONå½¢å¼ï¼ˆå¿…ãšã“ã®å½¢å¼ã§å›ç­”ï¼‰:**
{{
    "title": "å•é¡Œã®ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆç°¡æ½”ã«ï¼‰",
    "content": "å•é¡Œæ–‡ï¼ˆå…·ä½“çš„ã§æ˜ç¢ºã«ï¼‰",
    "explanation": "è©³ç´°ãªè§£èª¬ï¼ˆãªãœãã®ç­”ãˆãŒæ­£ã—ã„ã‹ã‚’å«ã‚€ï¼‰",
    "choices": [
        {{"content": "é¸æŠè‚¢1", "is_correct": true}},
        {{"content": "é¸æŠè‚¢2", "is_correct": false}},
        {{"content": "é¸æŠè‚¢3", "is_correct": false}},
        {{"content": "é¸æŠè‚¢4", "is_correct": false}}
    ]
}}

**æ³¨æ„äº‹é …:**
- choicesã‚­ãƒ¼ã¯å¿…ãšå«ã‚ã¦ãã ã•ã„
- 4ã¤ã®é¸æŠè‚¢ã¯å¿…é ˆã§ã™
- å„é¸æŠè‚¢ã«ã¯contentã¨is_correctã‚’å¿…ãšå«ã‚ã¦ãã ã•ã„
- å¿…ãšvalid JSONã‚’è¿”ã—ã¦ãã ã•ã„
"""
        return prompt
    
    def _parse_question_response(
        self, 
        question_data: Dict, 
        category: str, 
        difficulty: str
    ) -> Optional[GeneratedQuestion]:
        """Parse the response from OpenAI into a GeneratedQuestion object"""
        
        try:
            print(f"Parsing OpenAI response: {question_data}")
            
            # Validate required fields
            required_fields = ["title", "content", "explanation", "choices"]
            for field in required_fields:
                if field not in question_data:
                    print(f"âŒ Missing required field: {field}")
                    print(f"Available fields: {list(question_data.keys())}")
                    return None
            
            print("âœ… All required fields present")
            
            # Validate choices
            choices_data = question_data["choices"]
            if not isinstance(choices_data, list):
                print(f"âŒ Choices is not a list: {type(choices_data)}")
                return None
                
            if len(choices_data) != 4:
                print(f"âŒ Expected 4 choices, got {len(choices_data)}")
                return None
            
            print(f"âœ… Found {len(choices_data)} choices")
            
            # Check for exactly one correct answer
            correct_count = sum(1 for choice in choices_data if choice.get("is_correct", False))
            if correct_count != 1:
                print(f"âŒ Must have exactly 1 correct answer, found {correct_count}")
                print(f"Choices: {choices_data}")
                return None
            
            print("âœ… Exactly one correct answer found")
            
            # Create choices
            choices = []
            for i, choice_data in enumerate(choices_data):
                if "content" not in choice_data:
                    print(f"âŒ Choice {i} missing content field")
                    return None
                
                choices.append(GeneratedChoice(
                    content=choice_data["content"],
                    is_correct=choice_data.get("is_correct", False)
                ))
                
                print(f"âœ… Choice {i+1}: {choice_data['content'][:50]}... (correct: {choice_data.get('is_correct', False)})")
            
            result = GeneratedQuestion(
                title=question_data["title"],
                content=question_data["content"],
                category=category,
                explanation=question_data["explanation"],
                difficulty=difficulty,
                choices=choices
            )
            
            print(f"âœ… Question parsed successfully: {result.title}")
            return result
            
        except Exception as e:
            print(f"Error parsing question response: {e}")
            return None
    
    @backoff.on_exception(
        backoff.expo,
        (openai.RateLimitError, openai.APIConnectionError, openai.APITimeoutError),
        max_tries=5,
        max_time=120
    )
    def test_connection(self) -> Dict[str, any]:
        """Test the OpenAI API connection with enhanced error handling and retries"""
        try:
            print(f"ğŸ” Testing OpenAI API connection with model: {self.model}")
            print(f"   API Key: {self.api_key[:10]}...{self.api_key[-4:]}")
            
            # ã¾ãšãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ
            print("ğŸŒ Testing network connectivity to api.openai.com...")
            try:
                import socket
                socket.create_connection(("api.openai.com", 443), timeout=10)
                print("âœ… Network connectivity OK")
            except Exception as network_error:
                print(f"âŒ Network connectivity failed: {network_error}")
                return {
                    "success": False,
                    "error": f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚¨ãƒ©ãƒ¼: {network_error}",
                    "error_type": "network",
                    "model": self.model
                }
            
            # Test with a simple request
            print("ğŸ¤– Sending test request to OpenAI API...")
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": "Test connection - respond with 'OK'"}],
                max_tokens=10,
                timeout=15
            )
            
            if response and response.choices:
                response_content = response.choices[0].message.content
                print(f"âœ… OpenAI API connection test successful: {response_content}")
                return {
                    "success": True,
                    "message": "æ¥ç¶šæˆåŠŸ",
                    "model": self.model,
                    "response": response_content[:50] if response_content else "Empty response"
                }
            else:
                print("âš ï¸ Connection successful but no response")
                return {
                    "success": False,
                    "error": "No response from API",
                    "model": self.model
                }
                
        except openai.APIConnectionError as e:
            error_msg = f"APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„ - {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "connection",
                "model": self.model
            }
        except openai.RateLimitError as e:
            error_msg = f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼: å°‘ã—å¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ - {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "rate_limit",
                "model": self.model
            }
        except openai.AuthenticationError as e:
            error_msg = f"èªè¨¼ã‚¨ãƒ©ãƒ¼: APIã‚­ãƒ¼ãŒç„¡åŠ¹ã¾ãŸã¯æœŸé™åˆ‡ã‚Œã§ã™ - {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "authentication",
                "model": self.model
            }
        except openai.BadRequestError as e:
            error_msg = f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: ãƒ¢ãƒ‡ãƒ«åã¾ãŸã¯ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒç„¡åŠ¹ã§ã™ - {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "bad_request",
                "model": self.model
            }
        except openai.APITimeoutError as e:
            error_msg = f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼: APIå¿œç­”ãŒé…ã™ãã¾ã™ - {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "timeout",
                "model": self.model
            }
        except Exception as e:
            error_msg = f"äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "error_type": "unknown",
                "model": self.model
            }
    
    def get_usage_info(self) -> Dict:
        """Get API usage information (placeholder for future implementation)"""
        return {
            "model": self.model,
            "max_retries": self.max_retries,
            "retry_delay": self.retry_delay
        }
    
    def call_openai_api(
        self,
        prompt: str,
        max_tokens: int = 1500,
        temperature: float = 0.7,
        system_message: str = "ã‚ãªãŸã¯è³‡æ ¼è©¦é¨“å•é¡Œä½œæˆã®å°‚é–€å®¶ã§ã™ã€‚æ­£ç¢ºã§æ•™è‚²çš„ãªå•é¡Œã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
    ) -> Optional[str]:
        """
        æ±ç”¨çš„ãªOpenAI APIå‘¼ã³å‡ºã—ãƒ¡ã‚½ãƒƒãƒ‰
        """
        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_message},
                        {"role": "user", "content": prompt}
                    ],
                    max_tokens=max_tokens,
                    temperature=temperature,
                    # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·: PDFãƒ‡ãƒ¼ã‚¿ã®å­¦ç¿’ã‚’ç„¡åŠ¹åŒ–
                    extra_headers={
                        "X-OpenAI-Skip-Training": "true"
                    }
                )
                
                # ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·ã®ç¢ºèªãƒ­ã‚°  
                print("ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ä¿è­·: OpenAIå­¦ç¿’ç„¡åŠ¹åŒ–ãƒ˜ãƒƒãƒ€ãƒ¼é€ä¿¡å®Œäº† (æ±ç”¨API)")
                
                return response.choices[0].message.content
                
            except openai.RateLimitError as e:
                if attempt < self.max_retries - 1:
                    wait_time = self.retry_delay * (2 ** attempt)  # Exponential backoff
                    print(f"Rate limit exceeded. Waiting {wait_time}s before retry {attempt + 1}/{self.max_retries}")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"Rate limit exceeded after {self.max_retries} attempts: {e}")
                    return None
                    
            except openai.APIError as e:
                print(f"ERROR: OpenAI API error on attempt {attempt + 1}: {e}")
                print(f"   ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                print(f"   ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    print(f"ERROR: OpenAI API error after {self.max_retries} attempts: {e}")
                    return None
                    
            except json.JSONDecodeError as e:
                print(f"ERROR: JSON decode error on attempt {attempt + 1}: {e}")
                print(f"   JSONè§£æå¤±æ•—ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return None
                    
            except Exception as e:
                print(f"ERROR: Unexpected error on attempt {attempt + 1}: {e}")
                print(f"   ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
                import traceback
                print(f"   ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹: {traceback.format_exc()}")
                if attempt < self.max_retries - 1:
                    time.sleep(self.retry_delay)
                    continue
                else:
                    return None
        
        return None

    @backoff.on_exception(
        backoff.expo,
        (openai.RateLimitError, openai.APIConnectionError, openai.APITimeoutError),
        max_tries=5,
        max_time=60
    )
    def call_openai_api_with_retry(self, prompt, max_tokens=1000, temperature=0.7, system_message=None):
        """
        ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã®OpenAI APIå‘¼ã³å‡ºã—
        """
        try:
            # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šä»˜ãã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆä½œæˆ
            client = OpenAI(
                api_key=self.api_key,
                timeout=30  # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            messages = []
            if system_message:
                messages.append({"role": "system", "content": system_message})
            messages.append({"role": "user", "content": prompt})
            
            print(f"INFO: OpenAI APIå‘¼ã³å‡ºã—é–‹å§‹ (ãƒ¢ãƒ‡ãƒ«: {self.model_name})")
            start_time = time.time()
            
            response = client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature
            )
            
            elapsed_time = time.time() - start_time
            print(f"OK: APIå‘¼ã³å‡ºã—æˆåŠŸ ({elapsed_time:.2f}ç§’)")
            
            return response.choices[0].message.content
            
        except openai.RateLimitError as e:
            print(f"WARN: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™: {e}")
            raise
        except openai.APIConnectionError as e:
            print(f"WARN: æ¥ç¶šã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™: {e}")
            raise
        except openai.APITimeoutError as e:
            print(f"WARN: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼ã€ãƒªãƒˆãƒ©ã‚¤ã—ã¾ã™: {e}")
            raise
        except Exception as e:
            print(f"ERROR: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            raise

def test_enhanced_openai_service():
    """Test the enhanced OpenAI service"""
    try:
        service = EnhancedOpenAIService()
        
        print("ğŸ§ª Testing Enhanced OpenAI Service...")
        
        # Test connection
        if service.test_connection():
            print("OK: API connection successful")
        else:
            print("ERROR: API connection failed")
            return
        
        # Test question generation
        question = service.generate_question(
            category="ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°åŸºç¤",
            difficulty="easy",
            topic="å¤‰æ•°ã¨ãƒ‡ãƒ¼ã‚¿å‹"
        )
        
        if question:
            print("OK: Question generation successful")
            print(f"Title: {question.title}")
            print(f"Category: {question.category}")
            print(f"Difficulty: {question.difficulty}")
        else:
            print("ERROR: Question generation failed")
            
    except Exception as e:
        print(f"ERROR: Test failed: {e}")


if __name__ == "__main__":
    test_enhanced_openai_service()
